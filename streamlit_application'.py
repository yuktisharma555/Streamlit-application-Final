# -*- coding: utf-8 -*-
"""Streamlit Application'.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RNKOcpbql7OaqNuUru3Ggy7Q68P1OYeD
"""

from google.colab import files
uploaded = files.upload()   # upload your label_encoder_scikit.pkl

from google.colab import files
uploaded = files.upload()

# Make sure pyngrok and streamlit installed
!pip install --quiet pyngrok streamlit

from pyngrok import ngrok, conf
import time, os

# If you used Option A to set token, conf already has it.
# If you used Option B, set it here:
# conf.get_default().auth_token = os.environ["NGROK_AUTH_TOKEN"]

# Kill any previous tunnels just in case
ngrok.kill()

# Open a public HTTP tunnel on port 8501 (Streamlit default)
public_tunnel = ngrok.connect(addr=8501, proto="http")
print("Public URL (open this in a new browser tab):", public_tunnel.public_url)

# Run Streamlit in background (app.py must exist in current directory)
# Use nohup & so it keeps running while the cell completes
cmd = "nohup streamlit run app.py --server.port 8501 --server.address 0.0.0.0 > streamlit.log 2>&1 &"
os.system(cmd)
time.sleep(2)
print("Streamlit started in background. If the page doesn't load, check streamlit.log for errors.")

!pip install streamlit
!npm install -g cloudflared

!pip install --quiet scipy

!nohup streamlit run app.py --server.port 8501 --server.address 0.0.0.0 &

!cloudflared tunnel --url http://localhost:8501 --no-autoupdate

# Run this cell (Colab)
!pip install --quiet streamlit tensorflow pillow scikit-learn seaborn matplotlib scipy
# Install cloudflared (download .deb and install)
!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb
!apt install -y ./cloudflared-linux-amd64.deb

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import numpy as np
# import tensorflow as tf
# from PIL import Image, ImageOps, ImageFilter
# import io, pickle, traceback
# import matplotlib.pyplot as plt
# import seaborn as sns
# from sklearn.metrics import confusion_matrix
# 
# # -------- Page config --------
# st.set_page_config(page_title="ScannerID", layout="centered")
# st.title("ðŸ“  ScannerID â€” Scanner Identification System")
# 
# IMG_SIZE = (256, 256)
# 
# # -------- Helpers --------
# def safe_load_keras(path):
#     try:
#         return tf.keras.models.load_model(path)
#     except Exception as e:
#         st.sidebar.error(f"Failed loading {path}: {e}")
#         return None
# 
# def preprocess_for_cnn(pil_img):
#     """Return array (1,256,256,1) normalized."""
#     img = ImageOps.grayscale(pil_img)
#     img = img.filter(ImageFilter.MedianFilter(3))
#     img = img.resize(IMG_SIZE, resample=Image.BILINEAR)
#     arr = np.array(img).astype("float32") / 255.0
#     return arr.reshape(1, IMG_SIZE[0], IMG_SIZE[1], 1)
# 
# def compute_8_features(pil_img):
#     img = ImageOps.grayscale(pil_img).resize(IMG_SIZE, resample=Image.BILINEAR)
#     arr = np.array(img).astype("float32").ravel() / 255.0
#     mean_v = float(np.mean(arr)); std_v = float(np.std(arr)); median_v = float(np.median(arr))
#     min_v = float(np.min(arr)); max_v = float(np.max(arr))
#     # skew & kurtosis simple approximations (safe)
#     if std_v > 0:
#         skew_v = float(np.mean(((arr - mean_v) ** 3))) / (std_v ** 3 + 1e-12)
#         kurt_v = float(np.mean(((arr - mean_v) ** 4))) / (std_v ** 4 + 1e-12)
#     else:
#         skew_v = 0.0; kurt_v = 0.0
#     # entropy from histogram
#     hist, _ = np.histogram(arr, bins=256, range=(0.0,1.0), density=True)
#     hist = hist + 1e-12
#     ent_v = float(-np.sum(hist * np.log(hist)))
#     feat = np.array([mean_v, std_v, median_v, min_v, max_v, skew_v, kurt_v, ent_v], dtype="float32")
#     return feat.reshape(1, -1)
# 
# # -------- Load models (safe) --------
# @st.cache_resource
# def load_models():
#     info = {}
#     cnn = safe_load_keras("cnn_final_model.keras")
#     try:
#         with open("xgb_model.pkl", "rb") as f:
#             xgb = pickle.load(f)
#     except Exception as e:
#         xgb = None
#         info['xgb_err'] = str(e)
#     try:
#         with open("label_encoder_scikit.pkl", "rb") as f:
#             le = pickle.load(f)
#     except Exception as e:
#         le = None
#         info['le_err'] = str(e)
#     info['cnn_loaded'] = cnn is not None
#     info['xgb_loaded'] = xgb is not None
#     info['le_loaded'] = le is not None
#     return cnn, xgb, le, info
# 
# cnn_model, xgb_model, label_encoder, load_info = load_models()
# 
# # Sidebar diagnostics
# st.sidebar.header("Model status")
# st.sidebar.write(f"CNN loaded: {load_info.get('cnn_loaded', False)}")
# st.sidebar.write(f"XGBoost loaded: {load_info.get('xgb_loaded', False)}")
# st.sidebar.write(f"LabelEncoder loaded: {load_info.get('le_loaded', False)}")
# if 'xgb_err' in load_info:
#     st.sidebar.write("XGB load error: " + load_info['xgb_err'])
# if 'le_err' in load_info:
#     st.sidebar.write("LabelEncoder load error: " + load_info['le_err'])
# 
# # classes fallback
# if label_encoder is not None and hasattr(label_encoder, "classes_"):
#     classes = list(label_encoder.classes_)
# else:
#     classes = [
#         "Canon120-1","Canon120-2","Canon220","Canon9000-1","Canon9000-2",
#         "EpsonV39-1","EpsonV39-2","EpsonV370-1","EpsonV370-2","EpsonV550","HP"
#     ]
# 
# # -------- UI: select model mode --------
# mode = st.sidebar.selectbox("Prediction mode", ["CNN Only", "XGBoost Only", "Ensemble (CNN + XGB)"])
# 
# st.write("Upload image (png/jpg/jpeg/tif/tiff). Model will preprocess to 256Ã—256 grayscale for CNN and compute 8-d features for XGBoost.")
# 
# # session buffers for confusion matrix
# if "pred_labels" not in st.session_state: st.session_state.pred_labels = []
# if "true_labels" not in st.session_state: st.session_state.true_labels = []
# 
# # -------- File uploader (supports TIFF) --------
# uploaded = st.file_uploader("Upload scanner image", type=["png","jpg","jpeg","tif","tiff"])
# if uploaded is None:
#     st.info("Please upload an image to get a prediction.")
# else:
#     # Read image
#     try:
#         image = Image.open(io.BytesIO(uploaded.read())).convert("RGB")
#     except Exception as e:
#         st.error("Can't read uploaded image. Try saving it as PNG/JPG/TIFF and re-uploading.")
#         st.text(traceback.format_exc())
#         image = None
# 
#     if image is not None:
#         st.image(image, caption="Uploaded image", use_column_width=True)
# 
#         # Preprocess / features
#         cnn_input = None
#         xgb_feat = None
#         cnn_label = None
#         cnn_conf = None
#         xgb_label = None
#         warnings = []
# 
#         # CNN input
#         if cnn_model is not None:
#             try:
#                 cnn_input = preprocess_for_cnn(image)
#             except Exception as e:
#                 warnings.append(f"CNN preprocess failed: {e}")
# 
#         # XGB features
#         if xgb_model is not None:
#             try:
#                 xgb_feat = compute_image_features(image)
#             except Exception as e:
#                 warnings.append(f"XGB feature extraction failed: {e}")
# 
#         # Predict CNN
#         if cnn_model is not None and cnn_input is not None:
#             try:
#                 probs = cnn_model.predict(cnn_input)
#                 probs = np.array(probs)
#                 if probs.ndim == 1:
#                     probs = probs.reshape(1, -1)
#                 idx = int(np.argmax(probs[0]))
#                 cnn_label = classes[idx] if idx < len(classes) else f"class_{idx}"
#                 cnn_conf = float(np.max(probs[0]))
#             except Exception as e:
#                 warnings.append(f"CNN predict failed: {e}")
# 
#         # Predict XGB
#         if xgb_model is not None and xgb_feat is not None:
#             try:
#                 raw = xgb_model.predict(xgb_feat)
#                 val = raw[0] if isinstance(raw, (list, tuple, np.ndarray)) else raw
#                 try:
#                     xgb_label = label_encoder.inverse_transform([int(val)])[0]
#                 except Exception:
#                     xgb_label = str(val)
#             except Exception as e:
#                 warnings.append(f"XGBoost predict failed: {e}")
# 
#         # Ensemble logic
#         final_label = None
#         final_confidence = None
#         if mode == "CNN Only":
#             final_label = cnn_label; final_confidence = cnn_conf
#         elif mode == "XGBoost Only":
#             final_label = xgb_label; final_confidence = None
#         else:  # Ensemble
#             if cnn_label is not None and xgb_label is not None:
#                 if cnn_label == xgb_label:
#                     final_label = cnn_label; final_confidence = cnn_conf
#                 else:
#                     final_label = cnn_label if (cnn_conf is not None and cnn_conf >= 0.6) else xgb_label
#                     final_confidence = cnn_conf
#             else:
#                 final_label = cnn_label or xgb_label
#                 final_confidence = cnn_conf
# 
#         # Show prediction success in green with confidence if available
#         if final_label is not None:
#             if final_confidence is not None:
#                 st.success(f"ðŸ¥³ Hurray! Scanner Predicted: **{final_label}** â€” Accuracy: **{final_confidence:.2f}**")
#             else:
#                 st.success(f"ðŸ¥³ Hurray! Scanner Predicted: **{final_label}**")
#         else:
#             st.error("No prediction available. Check models and preprocessing.")
# 
#         # show model-level outputs
#         st.markdown("**Model outputs:**")
#         if cnn_label is not None:
#             st.write(f"- CNN â†’ **{cnn_label}** (conf: {cnn_conf:.3f})")
#         else:
#             st.write("- CNN â†’ (no result)")
#         if xgb_label is not None:
#             st.write(f"- XGBoost â†’ **{xgb_label}**")
#         else:
#             st.write("- XGBoost â†’ (no result)")
# 
#         if warnings:
#             with st.expander("Diagnostics / Warnings"):
#                 for w in warnings:
#                     st.warning(w)
# 
#         # Append predicted label to buffer (keep history)
#         st.session_state.pred_labels.append(final_label if final_label is not None else "Unknown")
# 
#         st.markdown("---")
# 
#         # ---------- Confusion Matrix ----------
#         st.header("ðŸ“Š Confusion Matrix")
# 
#         # default selection to predicted label
#         default_index = 0
#         if final_label in classes:
#             try:
#                 default_index = classes.index(final_label)
#             except Exception:
#                 default_index = 0
# 
#         true_choice = st.selectbox("Select TRUE label for this uploaded image (defaults to predicted):",
#                                    classes, index=default_index)
# 
#         if st.button("Add Sample to Confusion Matrix"):
#             st.session_state.true_labels.append(true_choice)
#             st.success("Added sample to evaluation buffer.")
# 
#         # show confusion matrix if enough samples
#         n_samples = min(len(st.session_state.true_labels), len(st.session_state.pred_labels))
#         if n_samples >= 2:
#             true_list = st.session_state.true_labels[:n_samples]
#             pred_list = st.session_state.pred_labels[:n_samples]
#             cm = confusion_matrix(true_list, pred_list, labels=classes)
# 
#             fig, ax = plt.subplots(figsize=(10, 10))
#             sns.heatmap(cm, annot=True, fmt='d', cmap="Blues", xticklabels=classes, yticklabels=classes, cbar=False,
#                         annot_kws={"size": 9})
#             ax.set_xlabel("Predicted Class")
#             ax.set_ylabel("Actual Class")
#             ax.set_title("Confusion Matrix")
#             plt.xticks(rotation=90)
#             plt.yticks(rotation=0)
#             st.pyplot(fig)
# 
# # Footer
# st.markdown("---")
# st.write("Notes: True labels must be provided by you; the selector defaults to the predicted label to save clicks.")
#

# Kill any old streamlit processes first (safe)
!pkill -f streamlit || true

# Start Streamlit in background with larger upload size (512 MB)
!nohup streamlit run app.py --server.port 8501 --server.address 0.0.0.0 --server.maxUploadSize 512 > streamlit.log 2>&1 &

# Let it boot and show the logs
import time, os
time.sleep(2)
print("Streamlit logs (last 200 lines):")
!tail -n 200 streamlit.log